% This is sigproc-sp.tex -FILE FOR V2.6SP OF ACM_PROC_ARTICLE-SP.CLS
% OCTOBER 2002
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V2.6SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.6SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
%
%  However, both the CopyrightYear (default to 2002) and the ACM Copyright Data
% (default to X-XXXXX-XX-X/XX/XX) can still be over-ridden by whatever the author
% inserts into the source .tex file.
% e.g.
% \CopyrightYear{2003} will cause 2003 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@acm.org
%
% For tracking purposes - this is V2.6SP - OCTOBER 2002

\documentclass{acm_proc_article-sp-sigmod09}
\usepackage{url}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{float}
\begin{document}
\algnewcommand\algorithmicforeach{\textbf{for each}}
\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}
%
% --- Author Metadata here ---
\conferenceinfo{Big Data and Social Networks}{Academic year 2018-2019}
%\setpagenumber{50}
%\CopyrightYear{2002} % Allows default copyright year (2002) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (X-XXXXX-XX-X/XX/XX) to be over-ridden.
% --- End of Author Metadata ---

\title{A data generator for frequent itemset mining in tree-like sequences of complex objects}
\numberofauthors{2}
\author{
\alignauthor
Nicol\`o Pomini\\
       \affaddr{Mat. 203319}\\
       \affaddr{University of Trento, Trento}\\
       \affaddr{nicolo.pomini@studenti.unitn.it}
\alignauthor
Marco Merlin\\
       \affaddr{Mat. 205263}\\
       \affaddr{University of Trento, Trento}\\
       \affaddr{marco.merlin@studenti.unitn.it}
}
\maketitle
\begin{abstract}
Data generation is essential to many companies nowadays, allowing to test data mining and processing applications using an almost unlimited amounts of data without being forced to buy it from third party businesses. While it is often true that generated data cannot have the same quality as real world data, it can still come pretty close by using parameterized generators, which can vary the generated data based on some parameters dictated by the user. Parameters allow to change the way the data is generated, and effectively simulate different real world scenarios. In the next chapters are described the algorithms, the methods used and the results obtained by developing a parameterized data generator for frequent itemsets in tree-like sequences of complex objects. Tree structures formed by complex objects are generated with dependencies between their attributes, meaning that some sequences of correlated attributes appear frequently in the generated trees. The generator uses different parameters to generate different patterns and change the dependencies between the attributes, so that many scenarios can be simulated. Further details about all the possible parameters can be red in the next chapters.
\end{abstract}

\terms{Data mining}

\keywords{Data generation, frequent itemset mining}

\section{Introduction}
Nowadays, the daily generation of data is growing exponentially. People, companies, sensors, IoT devices and many other things produce every day a huge amount of data: according to forbes.com\footnote{forbes.com/sites/bernardmarr/2018/05/21/how-much-data-do-we-create-every-day-the-mind-blowing-stats-everyone-should-read}, 2.5 quintillion bytes of data a day are generates. Thanks to these numbers, several fields of computer science related to data are also growing very fast. One of these is \emph{data mining}.

As suggested by its name, the aim of data mining is to discover and extract pattern, and more general information, from great amount of data. The larger the available dataset, the more accurate and meaningful the results. Data mining is a multidisciplinary subject which involves many techniques coming from many different fields such as computer science, statistics and data visualization.

A very well known task for data mining applications is the frequent itemset problem. In many scenarios, applications produce records that contain several fields, and these fields are not always completely independent from each other meaning that the appearance of one may imply the appearance of some others. For example, a list of purchases in a shop can contain similar patterns, or a call made by a web service to some external RESTful services may lead to further calls to other services.

This report is about the project for the \emph{Big Data and Social networks} course taking place in the department of information engineering and computer science\footnote{\url{www.disi.unitn.it}} in the university of Trento, Italy. The project is related to the \emph{data mining} course, taking place in the same department, and in particular to the course project of the latter. In fact, the purpose of the \emph{big data} project is to build a data generator for the \emph{data mining} project.

The report is organized as follows: in Chapter~2, the problem statement is formalized; in Chapter~3, some assumptions are stated, in Chapter~4 the data generation process is explained in its entirety, the Chapter~5 is about the implementation of the data generator, and finally, in Chapter~6, some details about the evaluation of the software are given.

\section{Problem statement}
The goal of this project is to create a data generator for the \emph{data mining} project. To better understand which are the constraints to consider, let us formalize the \emph{data mining} problem.

\subsection{Data mining problem statement}
A record $\boldsymbol{r}$ is a tuple, in the form $<a_1 \colon v_1, a_2 \colon v_2, \text{\dots}, a_n \colon v_n>$, where a pair $a_i \colon v_i$ represents an attribute-value relationship, where $a_i$ is the attribute and $v_i$ the value. These pairs can contain any kind of data, such as numbers or strings. To identify a record, it is assumed that each one has an attribute called \emph{record id}, or \texttt{rid} for short.

A transaction $\boldsymbol{T}$ is a set of records $\{\boldsymbol{r_1}, \boldsymbol{r_2}, \text{\dots}, \boldsymbol{r_m}\}$ that forms a tree structure, which means that a transaction has a root record, which has some \emph{children records}, which can have children themselves and so on. To identify the transaction to which each record belongs, it is assumed that every record has an attribute called \emph{transaction id}, or \texttt{tid} for short.

\begin{figure}
\centering
\epsfig{file=PatternExample.pdf}
\caption{An example of transaction, made of three records.}
\label{fig:transaction}
\end{figure}

Let us define a pattern.
\newdef{definition}{Definition}
\begin{definition}
A pattern is a set of ordered attributes and values belonging to possibly different records in the same transaction. In other words, a pattern is any ordered subset of $\bigcup\limits_{i=1}^{n} \bigcup\limits_{j=1}^{m} \boldsymbol{r_i}<a_j \colon v_j>$, where the ordering is given by the hierarchy of the transaction. For example, in Figure~\ref{fig:transaction} some possible example of pattern are $\{a_1 \colon v_1, a_3 \colon v_3\}$ or $\{a_2 \colon v_2, a_3 \colon v_3\}$, but not $\{a_4 \colon v_4, a_1 \colon v_1\}$, beacuse the latter breakes the hierarchic order.

A pattern has a tree structure, and it can be developed in three different ways.
\begin{itemize}
\item Horizontal -- which means that the pattern is made of a single record, with more than an attribute involved. This kind of pattern is a sort of a logical implication regarding two or more attributes in the same record, where the existence of a certain value implies the existence of some other values in the same record. Referring to Figure~\ref{fig:transaction}, the only possible horizontal pattern is $\{a_1 \colon v_1, a_2 \colon v_2\}$.
\item Vertical -- when the pattern involves more than one attribute, each coming from more than one record, creating a tree structure. In this case, at least two records must be involved in order for such a pattern to be observed, otherwise any frequent value -- like every \texttt{tid} -- would be a pattern. The records in which a value belonging to the pattern appears do not have to be contiguous: in fact, it is possible to have a pattern made of three nodes -- for example $x, y, z$, with $x$ parent of $y$ and $y$ parent of $z$, where the existance of a value in $x$ implies the existance of a value in $z$, with any possible value in $y$. Referring to Figure~\ref{fig:transaction}, the possible vertical patterns are $\{a_1 \colon v_1, a_3 \colon v_3\}$, $\{a_2 \colon v_2, a_3 \colon v_3\}$, $\{a_1 \colon v_1, a_4 \colon v_4\}$, $\{a_2 \colon v_2, a_4 \colon v_4\}$, but also $\{a_3 \colon v_3, a_4 \colon v_4\}$. The latter is an example of a non-contiguos pattern as the parent may contain any value and the children values imply each other. A pattern such as this tells us that every time a node has at least two children where one of them contains $a_3 \colon v_3$, we can expect another child to contain $a_4 \colon v_4$.
\item Horizontal and vertical -- the case of a vertical pattern, in which the records can have more than one attribute involved in the pattern. Referring to Figure~\ref{fig:transaction}, they can be $\{a_1 \colon v_1, a_2 \colon v_2, a_3 \colon v_3\}$, $\{a_1 \colon v_1, a_2 \colon v_2, a_4 \colon v_4\}$ or $\{a_1 \colon v_1, a_2 \colon v_2, a_3 \colon v_3, a_4 \colon v_4\}$.
\end{itemize}
\end{definition}

Given a set of transactions, the goal is to identify patterns of attributes that appear at least an $f$ number of times among all the transactions where $f$ can be set by the user.

\subsection{Big Data problem}
Starting from the data mining problem statement, the big data one is to create a set of records, which are organized in tree-structured transactions, making sure that among the transactions there exist some frequent pattern.

\section{Assumptions}
\label{sec:assumptions}
For the sake of simplification, some assumption exists.

All the records contain at least four attributes: the \texttt{rid} to identify the record; the \texttt{tid} to recognize to which transaction the record belongs; a \texttt{parent} field, containing the \texttt{rid} of the parent record -- which can be empty in case the considered record is the root of a transaction; at least another attribute, which can have any name and any type. The latter kind of attribute is called \emph{generic attribute}. The patterns are built and searched among \emph{generic attributes}, and not on the other three types, which should not and cannot form any pattern since they are used to describe the structure of the transactions.

\begin{definition}
A \emph{generic attribute} is any attribute of a record which is not the \texttt{rid}, the \texttt{tid} or the \texttt{parent} attributes. These attributes represent the features of each record, and the patterns are made of \emph{generic attributes}.
\end{definition}

All the records are assumed to have the same attributes -- some of them may be empty, to make the organization of the data easier. This contraint does not cause any loss of generality: in fact, in case the records are desired to be composed by a different number (and type) of attributes, it is sufficient to provide to each record all the attributes, leaving some of them empty. 

Furthermore, the output is assumed to be organized in a matrix $M \in \Sigma^{n \times d}$, where $\Sigma$ is the dictionary from which the values of the attributes belong to -- it can be a finite subset of $\mathbb{N}$, or a set of strings -- $n$ is the number of records, and $d$ the number of attributes per record.

\section{Data generation}
\label{sec:generation}
The data generation process is parameterized, in order to let the user to use the same tool to generate various scenarios in the same problem domain. The parameters are the following:
\begin{itemize}
\item the number of transaction $T$ to be generated, which is an integer;
\item the number of patterns $P$ to generate, which are distributed among the transactions -- this is also an integer number;
\item the average length of patterns $l$, which is a floating point number;
\item the number of fields $n$ that each record has, which is an integer -- as explained in Section~\ref{sec:assumptions}, the minimum value is 4;
\item a threshold $t$ that indicates the number of times a pattern should appear among all transactions in order to be frequent.
\end{itemize} 
The data generation process is structured as follows: firstly, the name of the fields of the records are generated; secondly, the patterns are generated; thirdly, the transactions are generated with a variable amount of previously generated patterns in them. In the following sub-sections these three steps are explained in detail. It is assumed that the dictionary data structure, with a method to add an object given its key -- $add(key, value)$ -- and a method to return a value by key (or $\bot$ when the key is not in the dictionary) -- $lookup(key)$ -- exists.

\subsection{Attribute generation}
The very first part of the data generation process is about the attributes of the records. According to the assumptions made in Section~\ref{sec:assumptions}, each record has three attributes whose role is to uniquely identify a record -- the \texttt{rid} -- and to structure and relate records among them -- the \texttt{tid} to understand which transaction each record belongs to, and the \texttt{parent} to define the record hierarchy. In addition to these three, there is a certain number of \emph{generic attributes} that characterize each record.

All the names of the possible \emph{generic attributes} are generated. Without loss of generality, they all are generated as strings -- since every object can be represented by a string and built from a string. In particular, $n - 3$ strings are generated, which represent the names of the attributes -- which can be also seen the keys or the field names. In other words, a vector $\boldsymbol{a}$ -- of $n - 3$ elements is created. It contains all the attribute names.

To do so, let us assume the existence of a function that generates a random string, every time unique:
\begin{verbatim}
string randomString()
\end{verbatim}
which is used to generate the \emph{generic attributes}.

With the Algorithm~\ref{generate_attributes}, $\boldsymbol{a}$ is generated.
\begin{algorithm}
\caption{Generate the attribute names and return a vector $\boldsymbol{a}$ that contains them.}
\label{generate_attributes}
\begin{algorithmic}[1]
\Function{generateAttributeNames}{Integer $n$}
\State $\boldsymbol{a} \gets new Integer[n - 3]$
\For{$i \gets 1 \text{ to } n$}
	\State $\boldsymbol{a}_i \gets \text{ \texttt{randomString() }} $ 
\EndFor
\Return $\boldsymbol{a}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Pattern generation}
Once the possible names and values of the fields are defined, the patterns can be generated. To do so, let us define a tree-based data structure -- called PatternTree -- used to represent the single nodes of the patterns.

\begin{table}[H]
\centering
\begin{tabular}{|ll|} \hline
\textbf{PatternTree} & \\ \hline
\textbf{parent} & PatternTree \\ \hline
\textbf{children} & PatternTree[] \\ \hline
\textbf{fields} & Dict[string, string] \\
\hline\end{tabular}
\caption{PatternTree object definition.}
\label{tab:patterntree}
\end{table}

As can be seen in Table~\ref{tab:patterntree}, the object is a generic tree with an arbitrary number of children for every node. Furthermore, the attribute \emph{fields} represent the list of fields that characterize the pattern: this means that the values contained in this attribute form the pattern itself. For example, if \emph{fields} of a given node is equal to $ \{ color : blue \} $, it means that in the pattern will appear a node with the attribute \emph{color} set to \emph{blue}. The attribute \emph{fields} is a dictionary, with attribute names as keys, and attribute values as the values. It does not contain the fields \texttt{rid}, \texttt{tid} and \texttt{parent}, because they are specific for a record, and not related to the pattern.

The generation of the patterns relies on three of the parameters listed at the beginning of Section~\ref{sec:generation}: the number of patterns to be generated $P$, the average length of a pattern $l$ and the number of global fields $n$.

Let $Pl$ be the length of a pattern, which represents the number of edges it contains. Consequently, the number of nodes in the pattern is $1 + Pl$. The value of $Pl$ is decided using a Poisson random variable with mean $l$. This type of random variable is chosen because it models events occurring successively and independently in a given time frame, and this scenario fits perfectly because the structure -- and the length -- of a single pattern is independent from the others. Furthermore, publications like \cite{agrawal1994fast} and \cite{ivancsy2006time} use the same approach during the pattern generation. For each node to be created, a number $k \le n - 3$ of field names is picked randomly from the vector $\boldsymbol{a}$ generated previously, and for each field name one value is randomly created with the function \texttt{randomString()}. All the nodes are saved into a set, called \emph{generated}.

Once $1 + Pl$ nodes are generated, another set is created, called \emph{included}. The latter represents the nodes exctacted from \emph{generated} to whom a parent node have been assigned. At the beginnig, this set is empty. Randomly, one node from \emph{generated} is taken and moved into \emph{included}, assigning to it a \texttt{null} parent ($\bot$ symbol): this is the root node of the pattern. 

In turn, each node in \emph{generated} is taken and moved into \emph{included}, assigning to it a parent picked from the latter set. In this way every tree takes shapes.

The Algorithm~\ref{generate_node} generates a single node, with $k \le n - 3$ fields, while the Algorithm~\ref{generate_patterns} generates $P$ patterns, choosing the length of each one using a Poisson random variable. The latter returns a list of PatternTree object, each one is the root node of a pattern.

\begin{algorithm}
\caption{Generate a node.}
\label{generate_node}
\begin{algorithmic}[1]
\Function{generateNode}{Integer $n$, String[] $\boldsymbol{a}$}
\State $fields \gets new Dictionary()$
\For{$i \gets 1 \text{ to } n$}
	\State $k \gets randomInt(1, n - 3)$
	\State $fieldName \gets \boldsymbol{a}_k$
	\State $fieldValue \gets \text{\texttt{randomString()}}$
	\State $fields.add(fieldName, fieldValue)$
\EndFor
\State $node \gets new PatternTree()$
\State $node_{fields} \gets fields$ \\
\Return $node$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Generate the patterns.}
\label{generate_patterns}
\begin{algorithmic}[1]
\Function{generatePatterns}{Integer $P$, float $l$, Integer $n$, String[] $\boldsymbol{a}$}
\State $patterns \gets \{\}$
\For{$i \gets 1 \text{ to } P$}
	\State $Pl \gets \lfloor Poisson(l) \rfloor$
	\State $generated \gets \{\}$
	\For{$j \gets 1 \text{ to } 1 + Pl$}
		\State $node \gets generateNode(n, \boldsymbol{a}) $ 
		\State $generated \gets generated \cup \{node\}$
	\EndFor
	\State $included \gets \{\}$
	\State $root \gets random\_item(generated)$
	\State $root_{parent} = \bot$
	\State $included \gets included \cup \{root\}$
	\State $generated \gets generated \setminus \{root\}$
	\For{$j \gets 1 \text{ to } 1 + Pl$}
		\State $node \gets generated[randomInt(0, |generated| - 1)]$
		\State $parent \gets included[randomInt(0, |included| - 1)]$
		\State $node_{parent} = parent$
		\State $included \gets included \cup \{node\}$
		\State $generated \gets generated \setminus \{node\}$
	\EndFor
	\State $patterns \gets patterns \cup \{root\}$
\EndFor
\Return $patterns$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Transaction generation}
After the patterns are generated, it is now time for the entire transactions to be created. To do so, another data structure based on trees is defined -- called TransactionTree -- in a similar way of the one in Table~\ref{tab:patterntree}.

\begin{table}[H]
\centering
\begin{tabular}{|ll|} \hline
\textbf{TransactionTree} & \\ \hline
\textbf{parent} & TransactionTree \\ \hline
\textbf{children} & TransactionTree[] \\ \hline
\textbf{rid} & string \\ \hline
\textbf{tid} & string \\ \hline
\textbf{fields} & Dict[string, string] \\
\hline\end{tabular}
\caption{TransactionTree object definition.}
\label{tab:transactiontree}
\end{table}

The object defined in Table~\ref{tab:transactiontree} adds to each record a \texttt{rid} and the \texttt{tid}: the former is unique for each record, while the latter is unique for each transaction. We also assume that the TransactionTree objects have a \texttt{getNodes()} method which returns an array containing the nodes which make up the tree (rooted in the node which calls the function).

Starting from the PatternTree objects generated in the previous step, they are converted into TransactionTree objects adding them a temporary \texttt{rid} (which will be changed later on). The \texttt{tid} is not set here, it will be added later. This transformation is done in Algorithm~\ref{translate_patterns}, which is initially called passing as PatternTree $t$ the root of a pattern, and as PatternTree $p$ a \texttt{null} value $\bot$. The function transforms every node of the pattern recursively. Note that this algorithm does not set anything else but the already defined pattern attributes, a temporary \texttt{rid}, the parent and the children. The \texttt{rid} is changed later on because each pattern is probably going to appear more than once and each of their nodes need to be unique. Same goes for the non-pattern fields; they are set later on so that they can be unique and random for each pattern's appearance. 

\begin{algorithm}
\caption{Transform a PatternTree into a TransactionTree.}
\label{translate_patterns}
\begin{algorithmic}[1]
\Function{translatePatterns}{PatternTree $t$, PatternTree $p$}
\State $rid \gets \text{ \texttt{randomString() }}$
\State $fields \gets t_{fields}$
\State $children \gets \{\}$
\For{$child \in t_{children}$}
	\State $children \gets children \cup \{translate\-Patterns(child, t)\}$
\EndFor
\State $node \gets new TransactionTree()$
\State $node_{rid} \gets rid$
\State $node_{children} \gets children$
\State $node_{fields} \gets fields$ \\
\Return $node$
\EndFunction
\end{algorithmic}
\end{algorithm}

The list of transformed pattern nodes will be referred as $TPatterns$ (Transformed patterns).

Next, a dictionary is created to determine in which transactions each pattern in $TPatterns$ will appear. This dictionary uses the elements of $TPatterns$ as keys, and integer arrays as values. The integer arrays contain the indexes of the transactions in which the pattern (its key) needs to be present. For example, if the algorithm is generating transaction number $k$ and the integer arrays associated with patterns $P1$ and $P2$ contain $k$, then both $P1$ and $P2$ will appear into transaction $k$. The number of transactions in which each pattern will appear is determined by the pattern size, meaning that shorter patterns will appear more often compared to bigger patterns. Furthermore, by definition, the patterns should be frequent, thus a minimum number of transactions in which each pattern will appear is guaranteed. The minimum frequency is determined by parameter $t$. Once the number of times each pattern should appear over all transactions is determined, the actual transactions in which each of them will appear are chosen randomly, meaning that a pattern may appear more than once in a given transaction $k$ if $k$ were to be picked more than once. Algorithm~\ref{generate_indexes} shows the exact procedure and formulas used to generate the pattern appearance dictionary. Line 5 shows the formula used to compute the number of times a given pattern should appear among all transactions where $minPatternNodes$ stands for the number of nodes in the smallest pattern, $maxPatternNodes$ stands for the number of nodes in the biggest pattern. Both of these values are computed by searching for the biggest and the smallest pattern in $TPatterns$.
\begin{algorithm}
\caption{Generate transaction indexes for all patterns.}
\label{generate_indexes}
\begin{algorithmic}[1]
\Function{GenerateIndexes\-Dictionary}{Transaction\-Tree[] $TPatterns$, Integer $maxNodes$, Integer $minNodes$, Integer $T$, Integer $t$}
\State $transactionIndexes \gets new Dictionary()$
\ForEach{$pattern \in TPatterns$}
	\State $k \gets T - (|pattern| - minPatternNodes) \times (T - t) / (max(1, maxPatternNodes - minPatternNodes))$
	\State $treeIndexes \gets [k]$
	\For{$i \gets 0 \text{ to } k - 1$}
		\State $treeIndexes[i] \gets \texttt{randomInt(0, T - 1)}$
	\EndFor
	\State $transactionIndexes.add(pattern, treeIndexes)$
\EndFor
\Return $transactionIndexes$
\EndFunction
\end{algorithmic}
\end{algorithm}

To better understand how this formula allows to determine the number of indexes to generate, let us suppose that we would like to compute the number of indexes for a pattern with 2 nodes, a pattern with 4 and a pattern with 6. Let us also suppose that the total number of transaction $T$ equals 100, that the minimum appearance threshold $t$ equals 20 and that the computed values for $minPatternNodes$ and $maxPatternNodes$ are 2 and 6 respectively. The number of appearances for the first pattern $k$ is going to be computed as (100 - (2 - 2) * (100 - 20) / (max(1, 6 - 2))). As we can notice, since the pattern is the smallest it can be, the whole right side of the formula is going to equal 0 because of the first expression (2 - 2) consequently, $k$ is going to equal $T$. This makes sense as the pattern is the smallest it could be and it should appear many times. Two things should be noted here: first, we chose $T$ as the maximum number of times a pattern should appear but any amount of times would be valid, second, even though a pattern should appear $T$ times it does not mean that it is going to appear in every transaction as the indexes are generated randomly and it may well be that the same index is generated more than once. For the second pattern the formula is going to be computed as (100 - (4 - 2) * (100 - 20) / (max(1, 6 - 2))). This time the right side of the expression is going to be equal to 40 and $k$ is going to equal $T$ - 40. This makes sense as the second pattern is twice as big compared to the first one and it should appear fewer times. For the last pattern the formula is going to be computed as (100 - (6 - 2) * (100 - 20) / (max(1, 6 - 2))). This time the right side of the expression is going to be equal to 80 and $k$ is going to equal $t$. Since the last pattern is the biggest, it makes sense for it to appear just enough times to make it frequent.

To sum it up, the formula makes so that the smallest patterns appear as many times as there are transactions, the biggest patterns appear just enough times to be frequent, and all the patterns in between appear an intermediate number of times between these two values.

Finally, the actual transactions are generated and this sequence of steps is repeated for each transaction: Firstly, a pattern list is created, and all the patterns which contain the transaction index in their index array generated with Algorithm~\ref{generate_indexes} are appended to it. This list will be named $chosenPatterns$ and the above described process can be seen in Algorithm \ref{pick_patterns}.


\begin{algorithm}
\caption{Pick the patterns for the current transaction being generated}
\label{pick_patterns}
\begin{algorithmic}[1]
\Function{PickPattern}{TransactionTree[] $tPatterns$, Dict(TransactionTree, Integer[]) $transactionIndexes$, Integer $currentTransactionIndex$}
\State $chosenPatterns \gets []$
\State $chosenPatternIndex \gets 0$
\ForEach{$pattern \in tPatterns$}
    \For{$i \gets 0 \text{ to } |transactionIndexes[pattern]| - 1$}
        \State $patternIndexesArray \gets transaction\-Indexes.lookup(pattern)$
        \If{$patternIndexesArray[i] = current\-Transaction\-Index$}
            \State $chosenPatterns[chosen\-Pattern\-Index] \gets pattern$
            \State $chosenPatternIndex \gets chosen\-Pattern\-Index + 1$
        \EndIf
    \EndFor
\EndFor
\Return $chosenPatterns$
\EndFunction
\end{algorithmic}
\end{algorithm}

Secondly, some $TransactionTree$ nodes are generated each with $n$ - 3 randomly generated attributes, plus a unique \texttt{rid} field. The number of generated nodes linearly depends on both the size of $chosenPattern$ list and on the $l$ parameter. These nodes serve the only purpose of adding random records to the transactions. This process is described in Algorithm \ref{generate_random_nodes}.

\begin{algorithm}
\caption{Generate the random nodes to be appended to the current transaction being generated}
\label{generate_random_nodes}
\begin{algorithmic}[1]
\Function{GenerateRandomNodes}{TransactionTree[] $chosenPatterns$, float $l$, Integer $n$, String[] $\boldsymbol{a}$}
\State $randomNodes \gets []$
\For{$i \gets 0 \text{ to } 1 + l \times (1 + |chosenPatterns|)$}
    \State $rid \gets \text{ \texttt{randomString() }}$
    \State $fieldsForRecord \gets new Dictionary()$
    \State $fieldsForRecord.add("rid", rid)$
    \State $fieldsForRecord.add("parent", \bot)$
    \For{$j \gets 0 \text{ to } n$}
        \State $fieldValue \gets \text{\texttt{randomString()}}$
        \State $fieldsForRecord.add(\boldsymbol{a}_j, fieldValue)$
    \EndFor
    \State $node \gets new TransactionTree()$ 
    \State $node_{fields} \gets fieldsForRecord$
    \State $randomNodes[i] \gets node$
\EndFor
\Return $randomNodes$
\EndFunction
\end{algorithmic}
\end{algorithm}

Thirdly, the randomly generated nodes and the $chosenPatterns$ elements are merged together into one list which will be called $nodesToAppend$, and an unique \texttt{tid} is assigned to each member of this list. Before the merging operation happens, a definitive unique \texttt{rid} is assigned to each node in each of the patterns in $chosenPatterns$ and all their missing fields are filled with random strings. A root for the transaction is then chosen randomly from the $nodesToAppend$ list. This process can be seen in Algorithm \ref{merging_lists}, Algorithm \ref{populate_pattern_node} and Algorithm \ref{transaction_generation}.

\begin{algorithm}
\caption{Randomly populates the missing fields of a node recursively}
\label{populate_pattern_node}
\begin{algorithmic}[1]
\Function{PopulatePatternNode}{TransactionTree $nodeToPopulate$, Integer $n$, String[] $\boldsymbol{a}$}
\State $nodeToPopulate_{rid} \gets \texttt{randomString()}$
\State $fields \gets nodeToPopulate_{fields}$
\For{$i \gets 1 \text{ to } n$}
	\If{$\boldsymbol{a}_i \notin fields$}
		\State $fields.add(\boldsymbol{a}_i, \text{\texttt{randomString()}})$
	\EndIf
\EndFor
\State $children \gets \{\}$
\For{$child \in nodeToPopulate_{children}$}
	\State $children \gets children \cup \{Populate\-Pattern\-Node(child, n, \boldsymbol{a})\}$
\EndFor
\Return $nodeToPopulate$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Merging of the two lists, assignment of the tid and missing fields}
\label{merging_lists}
\begin{algorithmic}[1]
\Function{MergeLists}{TransactionTree[] $chosenPatterns$, TransactionTree[] $randomNodes$, Integer n, String[] $\boldsymbol{a}$}
\State $tid = \text{ \texttt{randomString() }}$
\State $completeNodesList \gets []$
\For{$i \gets 0 \text{ to } |chosenPatterns| - 1$}
    \State $chosenPatterns[i] \gets Populate\-Pattern\-Node(chosenPatterns[i], n, \boldsymbol{a})$
    \State $chosenPatterns[i]_{tid} \gets tid$
    \State $completeNodesList[i] \gets chosenPatterns[i]$
\EndFor
\State $k \gets |chosenPatterns|$
\For{$i \gets k \text{ to } k + |randomNodes| - 1$}
    \State $randomNodes[i - k]_{tid} \gets tid$
    \State $completeNodesList[i] \gets randomNodes[i - k]$
\EndFor
\Return $completeNodesList$
\EndFunction
\end{algorithmic}
\end{algorithm}

Furthermore, another list called $currentTree$ is created, and its purpose is to store the nodes which are already part of the transaction; the root node, together with all the pattern nodes, if a pattern was chosen as root, is appended to this list.

Fourthly, as long as there are elements in the $nodesToAppend$ list, the algorithm will keep choosing random nodes from it and append them to nodes in the $currentTree$ list randomly. When a node is appended to the tree, it is deleted from the $nodesToAppend$ list and inserted into the $currentTree$ list, together with all the pattern nodes if the appended node is a pattern root. Once the $nodesToAppend$ list is empty, the transaction root is appended to the return array. This process is shown in Algorithm \ref{transaction_generation}. To sum it up, for each transaction to be generated function PickPattern (Algorithm \ref{pick_patterns}) is called to select the patterns that should appear in the transaction. Next, a number of random nodes to be appended to the transaction is generated using the GenerateRandomNodes function (Algorithm \ref{generate_random_nodes}). Next, a permanent \texttt{rid} is assigned to each node in each pattern that was selected for the transaction and all of their missing fields are filled with random values (Algorithm \ref{merging_lists} and Algorithm \ref{populate_pattern_node}). Next, using the function MergeLists (Algorithm \ref{merging_lists}), the chosen patterns and the randomly generated nodes are merged into one list. Finally, the function SingleTransactionGeneration (Algorithm \ref{transaction_generation}) is called to randomly append all the nodes in order to generate the transaction. This whole process is shown in Algorithm \ref{complete_transaction_generation}.

\begin{algorithm}
\caption{Generation of single transaction}
\label{transaction_generation}
\begin{algorithmic}[1]
\Function{SingleTransactionGeneration}{TransactionTree[] $completeNodesList$, TransactionTree[] $chosenPatterns$}
\State $transactionRoot \gets complete\-Nodes\-List[\texttt{randomInt(0, |completeNodesList| - 1)}]$
\State $currentTree \gets [transactionRoot]$
\State $currentTreeIndex \gets 1$
\If{$transactionRoot \in chosenPatterns$}
    \ForEach{$node \in transactionRoot.getNodes()$}
        \State $currentTree[currentTreeIndex] \gets node$
        \State $currentTreeIndex \gets currentTreeIndex + 1$
    \EndFor
\EndIf
\State $completeNodesList.remove(transactionRoot)$
\For{$i \gets 0 \text{ to } |completeNodesList| - 1$}
    \State $nodeToAppend \gets complete\-Nodes\-List[\texttt{randomInt(0, |completeNodesList| - 1)}]$
    \State $chosenParent \gets current\-Tree[\texttt{randomInt(0, |currentTree| - 1)}]$
    \State $nodeToAppend_{parent} \gets chosenParent_{rid}$
    \State $chosenParent_{children}.add(nodeToAppend)$
    \State $currentTree[currentTreeIndex] \gets node\-To\-Append$
    \State $currentTreeIndex \gets currentTreeIndex + 1$
    \If{$nodeToAppend \in chosenPatterns$}
        \ForEach{$node \in nodeToAppend.getNodes()$}
            \State $currentTree[currentTreeIndex] \gets node$
            \State $currentTreeIndex \gets current\-Tree\-Index + 1$
        \EndFor
    \EndIf
    \State $completeNodesList.remove(nodeToAppend)$
\EndFor
\Return $transactionRoot$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Generation of all transactions}
\label{complete_transaction_generation}
\begin{algorithmic}[1]
\Function{TransactionGeneration}{TransactionTree[] $TPatterns$, Integer $T$, float $l$, int $n$, String[] $\boldsymbol{a}$, Dict(TransactionTree, Integer) $transactionIndexes$}
\State $rootList \gets []$
\State $rootListIndex \gets 0$
\For{$index \gets 0 \text{ to } T - 1$}
    \State $chosenPatterns \gets \text{PickPattern(TPatterns, transactionIndexes, index)}$
    \State $randomNodes \gets \text{GenerateRandomNodes}(chosenPatterns, l, n, \boldsymbol{a})$
    \State $completeNodesList \gets \text{MergeLists(chosenPatterns, randomNodes)}$
    \State $transactionRoot \gets \text{SingleTransactionGeneration(completeNodesList, chosenPatterns)}$
    \State $rootList[rootListIndex] \gets transactionRoot$
    \State $rootListIndex \gets rootListIndex + 1$
\EndFor
\Return $rootList$
\EndFunction
\end{algorithmic}
\end{algorithm}

\section{Implementation}
The various steps and algorithms explained in Section~\ref{sec:generation} are implemented in a program, that takes as input the parameters listed in the previous section, and it produces a set of records organized in transactions, saving the generated data into a \texttt{csv} file. The latter has $n + 1$ rows, where the first line lists the names of the fields present inside each record, and the following $n$ lines contains the value of the fields, one record per line.

The software is written in Python\footnote{www.python.org}, and it makes use of the Numpy\footnote{http://www.numpy.org/} library \cite{oliphant2006guide} for manipulating arrays and matrices. The parameters are passed as arguments with flags and values when the program is started. The user can specify its own custom parameters, or use the default ones. It is also possible to set a flag to let the program print on the standard output which are the generated pattern. This way it is easy to test the correctness of the miner software that searches for these patterns.

To generate a random string, a Universally unique identifier -- \texttt{uuid} -- of 128 bit is generated, then it is converted to a hexadecimal number and then casted to string. To generate random integers, the standard random library of python is used.

\subsection{Use the software}
To use the software, it is mandatory to have a Python interpreter installed, at least with version 3.6, and to install the dependencies -- the libraries needed by the software -- by running the command \texttt{pip install -r requirements.txt}. To launch the software it is necessary to run the command \texttt{python src/main.py <arguments>}, with the following possible argument list:
\begin{itemize}
\item \texttt{-out filename}, to specify the filename on which the output is written. Default is \texttt{output}. Note that the extension \texttt{.csv} is automatically added, so passing the value \texttt{output} will produce a file named \texttt{output.csv};
\item \texttt{-t integer}, to specify how many transaction to generate. Default is 20;
\item \texttt{-p integer}, number of patterns to create. Default is 4;
\item \texttt{-avg float}, the average length of a pattern. Default is 3.0;
\item \texttt{-nf integer}, the number of fields each records will have. Default is 10;
\item \texttt{-avg integer}, the average length of a pattern. Default is 3;
\item \texttt{-thr integer}, the minimum number of times a pattern should appear. Default is 4;
\item \texttt{-pp boolean}, to print on the standard output the generated patterns. Default is \texttt{false};
\end{itemize}

\section{Evaluation}
The software is developed using an object oriented paradigm, and therefore it is composed by many small components that interact with each other. Each of this component has been tested, with several test cases, to verify its behaviour and its correctness.

In addition to that, some other tests have been performed, focused on the scalability. Since the application requires many parameters to work, some of them are kept constant in every test, like the maximum number of attributes a record can have $n$, the average pattern length $l$ and the threshold $t$ that indicates how many times a pattern has to appear to be considered frequent. In particular, the following values are used: $n = 10, l = 5.0, t = 5$. The only two varying parameters are $P$ and $T$. A total of four tests are performed with the parameter $P$ set equal to a constant $c$ multiplied by $T$. The testing software is launched with $c$ equal to 0.2, 0.5, 0.8, 1.0, and the response time of each test is saved and plotted with respect to $T$. For each test, the values of $T$ that are used are 10, 20, 50, 100, 200, 500, 1000. For each configuration, 5 tests are performed.

\begin{figure}
\centering
\epsfig{file=t02.pdf, scale=0.5}
\caption{Test results with $P = 0.2 * T$.}
\label{fig:zerotwo}
\end{figure}

\begin{figure}
\centering
\epsfig{file=t05.pdf, scale=0.5}
\caption{Test results with $P = 0.5 * T$.}
\label{fig:zerofive}
\end{figure}

\begin{figure}
\centering
\epsfig{file=t08.pdf, scale=0.5}
\caption{Test results with $P = 0.5 * T$.}
\label{fig:zeroeight}
\end{figure}

\begin{figure}
\centering
\epsfig{file=t1.pdf, scale=0.5}
\caption{Test results with $P = T$.}
\label{fig:one}
\end{figure}

The Figure~\ref{fig:zerotwo} shows the performances of the software with $c = 0.2$, the Figure~\ref{fig:zerofive} with $c = 0.5$, the Figure~\ref{fig:zeroeight} with $c = 0.8$ and the Figure~\ref{fig:one} with $c = 1.0$. Each of them plots the average response time of each configuration of the tests, and the colored region around the average line represents the minimum and the maximum response times, to show both best and a worst cases.

As it can be seen by the graphs, the parameter $P$ plays an important role in the outcomes, as higher values mean much greater average response times. The shapes of the four graphics are the same, but with different scales, because of $P$. The tests were performed on a machine with a 2.7 Ghz Intel Core i7 processor, and 16 GB of RAM.

\section{Conclusions}
In this report is described the used methods, the algorithms and the results obtained during the implementation of a parameterized generator for frequent item sets mining in tree-like sequences of complex objects. Python is used to implement a generator which adjusts its outcome based on parameters such as pattern average length to vary the size of the patterns, pattern number to vary the number of patterns which can appear and pattern frequency to vary the minimum frequency that a pattern must have. Finally, the behaviour of the software is tested as its input increases. Of course, both the randomness with which data is generated, and the respect of the given parameters may lead to very long executions, but on the other hand the outcome contains unbiased and complete results, with patterns of different nature, structure and distribution.

\subsection{Future works}
It is possible to work on the performances of the software, trying to parallelize as much as possible the process of generating data. In fact, once the name of the fields vector $\boldsymbol{a}$ is generated, it would be feasible to assign the generation of a single pattern to a specific thread. Since they would just read from $\boldsymbol{a}$, any synchronization protocol would not be needed in this phase.

In parallel, some other threads might start to generate the real patterns, with random length and random contents. Once all the patterns are generated, each thread would take in charge the pattern generated by itself and it would append it to some transaction. In this phase some synchronization procedures would be necessary, since a transaction can contain more than one pattern, and therefore more than one thread would try to concurrently modify a single transaction.

This approach should be effective specially with multi processors machines, like a server.


\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case

\end{document}
